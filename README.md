# Purpose
This repository contains a Python 3 implementation of a spelling corrector program detailed in this blog post by Peter Norvig (https://norvig.com/spell-correct.html). It uses identical methods to identify a set of candidate words; however it diverges by using categorical data analysis to select the correct spelling from the candidate words rather than selecting whichever candidate word has the highest frequency of occurrence in the English language. 

# Explanation
This spelling corrector creates a set of candidate words that the misspelled word is closest to and then selects one of the candidates to return as the correction. The methods this program uses to identify the set of candidate words is identical to the blog post referenced in the **Purpose** section and can be found here: (https://norvig.com/spell-correct.html). The novelty of this program is in how it selects a correction from the set of candidate words. 

It uses the chi-square goodness of fit test to analyze how closely the letter frequency of the misspelled word matches each of the candidate words and then selects the candidate word that most closely matches the misspelled word. A detailed explanation of the chi-square goodness of fit test can be found here: (https://www.statisticssolutions.com/chi-square-goodness-of-fit-test/). At a high-level, the chi square goodness of fit test is a test to see how closely an observed categorical distribution matches a hypothesized distribution. The categories here are letters so we are testing how closely the observed letter count from the misspelled word matches the hypothesized letter count of each candidate word. The test returns a test statistic which is linked to how closely the two distributions match and we return the candidate word with the lowest test statistic (the theoretical minimum of a chi-square test statistic is zero). The logic behind this approach is such: The misspelling is likely to have a similar letter frequency as the intended word. Letters may be misplaced or some may be missed, but the overall letter distributions should be similar. 

The theoretical strength of this method over simply selecting the candidate word with the highest frequency of occurrence in the English language is that it is likely to yield better results when the misspelled word is more uncommon. Take for example the word *nunnery*. Let's say we misspell nunnery as *nunner*. In this case, the words *runner* as well as *nunnery* would be in the candidate set. Because *runner* is more frequent than *nunnery*, we would never correctly identify the correct spelling using frequency selection. However; *nunnery* has a much closer letter distribution to the misspelling than *runner* does so we would correctly select *nunnery* as our correction. There is good reason to believe that this selection criteria is independent of the frequency of the target word. This is a desirable trait in a selection mechanism as uncommon words are likely to have a higher probability of being misspelled.

# Future Work
**Use different statistical tests:** The chi-square goodness of fit test is not the only test to identify how similar an observed categorical distribution is to a hypothesized one. The G-Test is another such test, and is promising as it tends to perform better with small sample sizes than the chi-square goodness of fit test. Further, the multinomial exact test is another test that is known to perform particularly well with small sample sizes; however, it is extremely computationally intensive and may be infeasible in this application, especially when the size of the candidate set is large.

**Verify independence of selection mechanism:** Currently, we are assuming that this selection mechanism is independent of the frequency of the target word. Actually assessing this hypothesis would give important information about one of the theorized strengths of the selection mechanism.


